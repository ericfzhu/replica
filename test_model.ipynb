{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# class FullSizeTestDataset(Dataset):\n",
    "#     def __init__(self, directory):\n",
    "#         self.directory = directory\n",
    "#         self.image_files = [os.path.join(directory, f) for f in os.listdir(directory)]\n",
    "#         self.transform = transforms.Compose([\n",
    "#             transforms.ToTensor(),\n",
    "#             # Add any other transformations here\n",
    "#         ])\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.image_files)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         img_path = self.image_files[idx]\n",
    "#         img = Image.open(img_path)\n",
    "#         img = img.resize((2048, 1536))  # Resize if necessary to handle edge cases\n",
    "#         patches = self.image_to_patches(img)\n",
    "#         return patches\n",
    "\n",
    "#     def image_to_patches(self, img):\n",
    "#         # Assuming img is a PIL image\n",
    "#         patches = []\n",
    "#         for i in range(0, img.width, 100):\n",
    "#             for j in range(0, img.height, 100):\n",
    "#                 # Handle edge cases for the last row and column\n",
    "#                 width, height = min(100, img.width - i), min(100, img.height - j)\n",
    "#                 patch = img.crop((i, j, i+width, j+height))\n",
    "#                 patch = self.transform(patch)\n",
    "#                 patches.append(patch)\n",
    "#         return torch.stack(patches)  # Return a tensor of all patches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your model\n",
    "import torch\n",
    "import numpy as np\n",
    "from model import ResNeXt\n",
    "from dataloader import get_dataloaders\n",
    "from torchvision.utils import save_image\n",
    "model = ResNeXt().to('cuda')\n",
    "epoch = 10000\n",
    "\n",
    "checkpoint = torch.load(f'checkpoints/model_epoch_{epoch}.pth')\n",
    "model.load_state_dict(checkpoint['generator_state_dict'])\n",
    "\n",
    "# Prepare DataLoader\n",
    "batch_size = 50\n",
    "sample_size = 100\n",
    "train_loader, test_loader = get_dataloaders(batch_size=batch_size, sample_size=sample_size)\n",
    "# test_dataset = FullSizeTestDataset('data/iphone/test_data/full_size_test_images')\n",
    "# test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# Evaluate\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(test_loader, 0):\n",
    "        real, target = data\n",
    "        real = real.to('cuda')\n",
    "        target = target.to('cuda')\n",
    "        output = model(real)\n",
    "        comparison = torch.cat((real[0], output[0]), dim=2)\n",
    "        save_image(comparison, f'images/output_{i}.jpg')\n",
    "        if i == 4:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability that a person who redeemed the coupon received email A is: 0.50\n"
     ]
    }
   ],
   "source": [
    "# Given probabilities\n",
    "P_A = 0.5\n",
    "P_B = 0.5\n",
    "P_R_given_A = 0.1 * 0.4  # P(R|A) = P(R|open and A) * P(open|A)\n",
    "P_R_given_B = 0.2 * 0.2  # P(R|B) = P(R|open and B) * P(open|B)\n",
    "\n",
    "# Calculate P(A|R) using Bayes' theorem\n",
    "P_A_given_R = (P_R_given_A * P_A) / (P_R_given_A * P_A + P_R_given_B * P_B)\n",
    "\n",
    "print(f\"The probability that a person who redeemed the coupon received email A is: {P_A_given_R:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "def processExecution(power, minPower, maxPower):\n",
    "    n = len(power)\n",
    "    ranges = list(zip(minPower, maxPower))\n",
    "    num_ranges = len(ranges)\n",
    "    result = [[0, 0] for _ in range(num_ranges)]\n",
    "    \n",
    "    queue = deque()\n",
    "    curr_range = 0\n",
    "    \n",
    "    for val in power:\n",
    "        # Add the current value to the queue\n",
    "        queue.append(val)\n",
    "        \n",
    "        # Update the result for the current range\n",
    "        while curr_range < num_ranges and val >= ranges[curr_range][0]:\n",
    "            if val <= ranges[curr_range][1]:\n",
    "                result[curr_range][0] += 1\n",
    "                result[curr_range][1] += val\n",
    "            curr_range += 1\n",
    "        \n",
    "        # Remove values from the queue that are outside the current range\n",
    "        while queue and queue[0] < ranges[curr_range][0]:\n",
    "            queue.popleft()\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 11], [0, 0]]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processExecution([11, 11, 11], [8,13], [11, 100])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DSLR-ResNeXt-sCYE6uU5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
